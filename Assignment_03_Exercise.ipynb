{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaunak-Mukherjee/ECE570-Artificial-Intelligence/blob/main/Assignment_03_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmwWs4S9cRIn"
      },
      "source": [
        "# ECE 57000 Assignment 3 Exercise\n",
        "\n",
        "Your Name:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7PCeyTdv4Ku"
      },
      "source": [
        "Prepare the pacakge we will use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMFxWrQfv4Kv"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import List, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmlsa88cqmib"
      },
      "source": [
        "## Exercise 0: Train your model on GPU (0 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfirXJR3qvB0"
      },
      "source": [
        "Some tasks in this assignment can take a long time if you run it on the CPU. For example, based on our solution of Exercise 3 Task 4 (Transfer Learning: finetuning of a pretrained model (resnet18)), it will take roughly 2 hours to train the model end-to-end (complete model and not only the last fc layer) for 1 epoch on CPU. Hence, we highly recommend you try to train your model on GPU.\n",
        "\n",
        "To do so, first you need to enable GPU on Colab (this will restart the runtime). Click `Runtime`-> `Change runtime type` and select the `Hardware accelerator` there.  You can then run the following code to see if the GPU is correctly initialized and available.\n",
        "\n",
        "**Note**: If you would like to avoid GPU overages on Colab, we would suggest writing and debugging your code before switching on the GPU runtime. Otherwise, the time you spent debugging code will likely count against your GPU usage. Once you have the code running, you can switch on the GPU runtime and train the model much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT7wKvilvBvX"
      },
      "outputs": [],
      "source": [
        "print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnPPDoA7vQWp"
      },
      "source": [
        "### You must manually move your model and data to the GPU (and sometimes back to the cpu)\n",
        "After setting the GPU up on colab, then you should put your **model** and **data** to GPU. We give a simple example below. You can use `to` function for this task. See [torch.Tensor.to](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) to move a tensor to the GPU (probably your mini-batch of data in each iteration) or [torch.nn.Module.to](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to) to move your NN model to GPU (assuming you create subclass [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)). Note that `to()` of tensor returns a NEW tensor while `to` of a NN model will apply this in-place. To be safe, the best semantics are `obj = obj.to(device)`. For printing, you will need to move a tensor back to the CPU via the `cpu()` function.\n",
        "\n",
        "Once the model and input data are on the GPU, everything else can be done the same.  This is the beauty of PyTorch GPU acceleration.  None of the other code needs to be altered.\n",
        "\n",
        "To summarize, you need to 1) enable GPU acceleration in Colab, 2) put the model on the GPU, and 3) put the input data (i.e., the batch of samples) onto the GPU using `to()` after it is loaded by the data loaders (usually you only put one batch of data on the GPU at a time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUdR8v7Kt-6S"
      },
      "outputs": [],
      "source": [
        "rand_tensor = torch.rand(5,2)\n",
        "simple_model = nn.Sequential(nn.Linear(2,10), nn.ReLU(), nn.Linear(10,1))\n",
        "print(f'input is on {rand_tensor.device}')\n",
        "print(f'model parameters are on {[param.device for param in simple_model.parameters()]}')\n",
        "print(f'output is on {simple_model(rand_tensor).device}')\n",
        "\n",
        "# device = torch.device('cuda')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# ----------- <Your code> ---------------\n",
        "# Move rand_tensor and model onto the GPU device\n",
        "\n",
        "\n",
        "# --------- <End your code> -------------\n",
        "print(f'input is on {rand_tensor.device}')\n",
        "print(f'model parameters are on {[param.device for param in simple_model.parameters()]}')\n",
        "print(f'output is on {simple_model(rand_tensor).device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz2T0QYYpwVR"
      },
      "source": [
        "## Exercise 1: Why use a CNN rather than only fully connected layers? (40 points)\n",
        "\n",
        "In this exercise, you will build two models for the **MNIST** dataset: one uses only fully connected layers and another uses a standard CNN layout (convolution layers everywhere except the last layer is fully connected layer). Note, you will need to use cross entropy loss as your objective function. The two models should be built with roughly the same accuracy performance, your task is to compare the number of network parameters (a huge number of parameters can affect training/testing time, memory requirements, overfitting, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8SpN1kv4Kz"
      },
      "source": [
        "### Task 1: Prepare train and test function\n",
        "\n",
        "We will create our train and test procedure in these two functions. The train function should apply one epoch of training. The functions inputs should take everything we need for training and testing and return some logs.\n",
        "\n",
        "#### Arguments requirement:\n",
        "* For the `train` function, it takes the `model`, `loss_fn`, `optimizer`, `train_loader`, and `epoch` as arguments.\n",
        "    * `model`: the classifier, or deep neural network, should be an instance of `nn.Module`.\n",
        "    * `loss_fn`: the loss function instance. For example, `nn.CrossEntropy()`, or `nn.L1Loss()`, etc.\n",
        "    * `optimizer`: should be an instance of `torch.optim.Optimizer`. For example, it could be `optim.SGD()` or `optim.Adam()`, etc.\n",
        "    * `train_loader`: should be an instance of `torch.utils.data.DataLoader`.\n",
        "    * `epoch`: the current number of epoch. Only used for log printing.(default: 1.)\n",
        "\n",
        "* For the `test` function, it takes all the inputs above except for the optimizer (and it takes a test loader instead of a train loader).\n",
        "\n",
        "#### Log requirement:\n",
        "Here are some further requirements:\n",
        "* In the `train` function, print the log 8-10 times per epoch. The print statement should be:\n",
        "```python\n",
        "print(f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}] Loss: {loss.item():.3f}')\n",
        "```\n",
        "* In the `test` function, print the log after the testing. The print statement is:\n",
        "```python\n",
        "print(f\"Test result on epoch {epoch}: total sample: {total_num}, Avg loss: {test_stat['loss']:.3f}, Acc: {100*test_stat['accuracy']:.3f}%\")\n",
        "```\n",
        "\n",
        "#### Return requirement\n",
        "* The `train` function should return a list, which the element is the loss per batch, i.e., one loss value for every batch.\n",
        "* The `test` function should return a dictionary with three keys: \"loss\", \"accuracy\", and \"prediction\". The values are the average loss of all the testset, average accuracy of all the test dataset, and the prediction of all test dataset.\n",
        "\n",
        "#### Other requirement:\n",
        "* In the `train` function, the model should be updated in-place, i.e., do not copy the model inside `train` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Fpdi_uv4Kz"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module,\n",
        "          loss_fn: nn.modules.loss._Loss,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          train_loader: torch.utils.data.DataLoader,\n",
        "          epoch: int=0)-> List:\n",
        "    # ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ----------- <End Your code> ---------------\n",
        "    assert len(train_loss) == len(train_loader)\n",
        "    return train_loss\n",
        "\n",
        "def test(model: nn.Module,\n",
        "         loss_fn: nn.modules.loss._Loss,\n",
        "         test_loader: torch.utils.data.DataLoader,\n",
        "         epoch: int=0)-> Dict:\n",
        "    # ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ----------- <Your code> ---------------\n",
        "    # dictionary should include loss, accuracy and prediction\n",
        "    assert \"loss\" and \"accuracy\" and \"prediction\" in test_stat.keys()\n",
        "    # \"prediction\" value should be a 1D tensor\n",
        "    assert len(test_stat[\"prediction\"]) == len(test_loader.dataset)\n",
        "    assert isinstance(test_stat[\"prediction\"], torch.Tensor)\n",
        "    return test_stat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFKqew7r-E-q"
      },
      "source": [
        "### Task 2: Following the structure used in the instructions, you should create\n",
        "\n",
        "*   One network named `OurFC` which should consist with only fully connected layers\n",
        "\n",
        "  *   You should decide how many layers and how many hidden dimensions you want in your network\n",
        "  *   Your final accuracy on the test dataset should lie roughly around 97% ($\\pm$2%)\n",
        "  *   There is no need to make the neural network unnecessarily complex, your total training time should no longer than 3 mins\n",
        "\n",
        "*   Another network named `OurCNN` which applys a standard CNN structure\n",
        "  *   Again, you should decide how many layers and how many channels you want for each layer.\n",
        "  *   Your final accuracy on the test dataset should lie roughly around 97% ($\\pm$2%)\n",
        "  *   A standard CNN structure can be composed as **[Conv2d, MaxPooling, ReLU] x num_conv_layers + FC x num_fc_layers**\n",
        "\n",
        "* Train and test your network on MNIST data as in the instructions.\n",
        "* Notice You can always use the `train` and `test` function you write throughout this assignment.\n",
        "* The code below will also print out the number of parameters for both neural networks to allow comparison.\n",
        "* (You can use multiple cells if helpful but make sure to run all of them to receive credit.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XfvgD-jt-Ye"
      },
      "outputs": [],
      "source": [
        "# Download MNIST and transformation\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> -------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccYESqrsxNXA"
      },
      "outputs": [],
      "source": [
        "# Build OurFC class and OurCNN class.\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> -------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxhAyKGCx_iC"
      },
      "outputs": [],
      "source": [
        "# Let's first train the FC model. Below are there common hyperparameters.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "max_epoch = 3\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX8q9Dtqylks"
      },
      "outputs": [],
      "source": [
        "# Let's then train the OurCNN model.\n",
        "start = time.time()\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIVO5T4JgA_N"
      },
      "outputs": [],
      "source": [
        "ourfc = OurFC()\n",
        "total_params = sum(p.numel() for p in ourfc.parameters())\n",
        "print(f'OurFC has a total of {total_params} parameters')\n",
        "\n",
        "ourcnn = OurCNN()\n",
        "total_params = sum(p.numel() for p in ourcnn.parameters())\n",
        "print(f'OurCNN has a total of {total_params} parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5oMKOrhmfpM"
      },
      "source": [
        "Questions (0 points, just for understanding): Which one has more parameters?  Which one is likely to have less computational cost when deployed? Which one took longer to train?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "290mOBEHgEXr"
      },
      "source": [
        "## Exercise 2: Train classifier on CIFAR-10 data. (30 points)\n",
        "Now, lets move our dataset to color images. CIFAR-10 dataset is another widely used dataset. Here all images have colors, i.e each image has 3 color channels instead of only one channel in MNIST. You need to pay more attention to the dimension of the data as it passes through the layers of your network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHClZywoGwWt"
      },
      "source": [
        "### Task 1: Create data loaders\n",
        "* Load CIFAR10 train and test datas with appropriate composite transform where the normalize transform should be `transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])`.\n",
        "* Set up a `train_loader` and `test_loader` for the CIFAR-10 data with a batch size of 9 similar to the instructions.\n",
        "* The code below will plot a 3 x 3 subplot of images including their labels. (do not modify)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANpwc7CSPlYP"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Create the appropriate transform, load/download CIFAR10 train and test datasets with transform\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------\n",
        "\n",
        "# Define trainloader and testloader\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------\n",
        "\n",
        "# Code to display images\n",
        "batch_idx, (images, targets) = next(enumerate(train_loader)) #fix!!!!!\n",
        "fig, ax = plt.subplots(3,3,figsize = (9,9))\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        image = images[i*3+j].permute(1,2,0)\n",
        "        image = image/2 + 0.5\n",
        "        ax[i,j].imshow(image)\n",
        "        ax[i,j].set_axis_off()\n",
        "        ax[i,j].set_title(f'{classes[targets[i*3+j]]}')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0FMDyDzijEG"
      },
      "source": [
        "### Task 2: Create CNN and train it\n",
        "Set up a convolutional neural network and have your data trained on it. You have to decide all the details in your network, overall your neural network should meet the following standards to receive full credit:\n",
        "\n",
        "*   You should not use more than three convolutional layers and three fully connected layers\n",
        "*   Accuracy on the test dataset should be **above** 50%\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1pkwtIAzwfg"
      },
      "outputs": [],
      "source": [
        "# Create CNN network.\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRuEf8tAlnsP"
      },
      "outputs": [],
      "source": [
        "# Train your neural network here.\n",
        "start = time.time()\n",
        "max_epoch = 4\n",
        "# ----------- <Your code> ---------------\n",
        "# Define net\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------\n",
        "output = test(net, criterion, test_loader, epoch)\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS1mXr9Cl6pM"
      },
      "source": [
        "### Task 3: Plot misclassified test images\n",
        "Plot some misclassified images in your test dataset:\n",
        "\n",
        "*   select three images that are **misclassified** by your neural network\n",
        "*   label each images with true label and predicted label\n",
        "*   use `detach().cpu()` when plotting images if the image is in gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd8vWof8nIHw"
      },
      "outputs": [],
      "source": [
        "total_images = 3\n",
        "predictions = output['prediction']\n",
        "targets = torch.tensor(testset.targets)\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2ZVJYKtL5yN"
      },
      "source": [
        "Questions (0 points): Are the mis-classified images also misleading to human eyes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INN54zXpTcZw"
      },
      "source": [
        "## Exercise 3: Transfer Learning (30 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgDHswfp0k7m"
      },
      "source": [
        "In practice, people won't train an entire CNN from scratch, because it is relatively rare to have a dataset of sufficient size (or sufficient computational power). Instead, it is common to pretrain a CNN on a very large dataset and then use the CNN either as an initialization or a fixed feature extractor for the task of interest.\n",
        "\n",
        "In this task, you will learn how to use a pretrained CNN for CIFAR-10 classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f21CjwoW8ty5"
      },
      "source": [
        "### Task1: Load pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ-21Pv183TX"
      },
      "source": [
        "`torchvision.models` (https://pytorch.org/vision/stable/models.html) contains definitions of models for addressing different tasks, including: image classification, pixelwise semantic segmentation, object detection, instance segmentation, person keypoint detection and video classification.\n",
        "\n",
        "First, you should load the **pretrained** ResNet-18 that has already been trained on [ImageNet](https://www.image-net.org/) using `torchvision.models`. If you are interested in more details about Resnet-18, read this paper https://arxiv.org/pdf/1512.03385.pdf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaHP0VfAVuDY"
      },
      "outputs": [],
      "source": [
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18 = resnet18.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQkZUZH84q8"
      },
      "source": [
        "### Task2: Create data loaders for CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTlRo-CJ4GQD"
      },
      "source": [
        "Then you need to create a modified dataset and dataloader for CIFAR-10. Importantly, the model you load has been trained on **ImageNet** and it expects inputs as mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be **at least** 224. So you need to preprocess the CIFAR-10 data to make sure it has a height and width of 224. Thus, you should add a transform when loading the CIFAR10 dataset (see [`torchvision.transforms.Resize`](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Resize)).\n",
        "This should be added appropriately to the `transform` you created in a previous task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhFys7OQV1Wj"
      },
      "outputs": [],
      "source": [
        "# Create your dataloader here\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8nR_aBi9Atb"
      },
      "source": [
        "### Task3: Classify test data on pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8IXXu-J9grR"
      },
      "source": [
        "Use the model you load to classify the **test** CIFAR-10 data and print out the test accuracy.\n",
        "\n",
        "Don't be surprised if the accuracy is bad!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOuCodyJ4FYp"
      },
      "outputs": [],
      "source": [
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETLezHR0-ByE"
      },
      "source": [
        "### Task 4: Fine-tune (i.e., update) the pretrained model for CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbQrsL-U-Faq"
      },
      "source": [
        "Now try to improve the test accuracy. We offer several possible solutions:\n",
        "\n",
        "(1) You can try to directly continue to train the model you load with the CIFAR-10 training data.\n",
        "\n",
        "(2) For efficiency, you can try to freeze part of the parameters of the loaded models. For example, you can first freeze all parameters by\n",
        "\n",
        "```\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "```\n",
        "and then unfreeze the last few layers by setting `somelayer.requires_grad=True`.\n",
        "\n",
        "You are also welcome to try any other approach you can think of.\n",
        "\n",
        "\n",
        "**Note:** You must print out the test accuracy and to get full credits, the test accuracy should be at least **80%**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaA_dukw-hLt"
      },
      "outputs": [],
      "source": [
        "# Directly train the whole model.\n",
        "start = time.time()\n",
        "#----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------\n",
        "test(resnet18, criterion, test_loader, epoch)\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53-9dPymv4K5"
      },
      "outputs": [],
      "source": [
        "# Load another resnet18 instance, only unfreeze the outer layers.\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY-yaF0YAyk7"
      },
      "outputs": [],
      "source": [
        "# Train the model!!\n",
        "start = time.time()\n",
        "# ----------- <Your code> ---------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------- <End Your code> ---------------\n",
        "test(resnet18, criterion, test_loader)\n",
        "end = time.time()\n",
        "print(f'Finished Training after {end-start} s ')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}